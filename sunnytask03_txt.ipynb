{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HueP_008WhWh",
        "outputId": "49959b7f-bf5d-4940-fde5-6d774d462d1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Word-level Markov Chain ===\n",
            "technology machine learning and deep learning and deep learning and deep learning and deep learning and deep learning are subsets of technology machine learning are used for text generation in\n",
            "\n",
            "=== Character-level Markov Chain ===\n",
            "p leare is of AI.\n",
            "           Mare used deep learnin natificial Intext ge is of AI.\n",
            "    AI.\n",
            "       Machins arnine proce used deep learning.\n",
            "    AI.\n",
            "      Machaing.\n",
            "    Marning.\n",
            "       Marnins the usets\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "class MarkovChainTextGenerator:\n",
        "    def __init__(self, mode=\"word\", n=2):\n",
        "        \"\"\"\n",
        "        :param mode: \"word\" or \"char\" (type of Markov chain)\n",
        "        :param n: size of n-grams (default=2 â†’ bigram)\n",
        "        \"\"\"\n",
        "        self.mode = mode\n",
        "        self.n = n\n",
        "        self.model = defaultdict(list)\n",
        "\n",
        "    def train(self, text):\n",
        "        \"\"\"\n",
        "        Train the Markov chain model on input text.\n",
        "        :param text: input string\n",
        "        \"\"\"\n",
        "        if self.mode == \"word\":\n",
        "            sequence = re.findall(r\"\\b\\w+\\b\", text.lower())  # tokenize words\n",
        "        elif self.mode == \"char\":\n",
        "            sequence = list(text)  # split into characters\n",
        "        else:\n",
        "            raise ValueError(\"Mode must be 'word' or 'char'\")\n",
        "\n",
        "        for i in range(len(sequence) - self.n):\n",
        "            key = tuple(sequence[i:i + self.n - 1])\n",
        "            next_item = sequence[i + self.n - 1]\n",
        "            self.model[key].append(next_item)\n",
        "\n",
        "    def generate(self, length=50, seed=None):\n",
        "        \"\"\"\n",
        "        Generate new text using the trained model.\n",
        "        :param length: number of tokens (words/chars) in output\n",
        "        :param seed: starting token(s)\n",
        "        \"\"\"\n",
        "        if not self.model:\n",
        "            raise ValueError(\"Model is empty. Train it first!\")\n",
        "\n",
        "        if seed is None:\n",
        "            seed = random.choice(list(self.model.keys()))\n",
        "        elif isinstance(seed, str) and self.mode == \"word\":\n",
        "            seed = tuple([seed.lower()])\n",
        "        elif isinstance(seed, str) and self.mode == \"char\":\n",
        "            seed = tuple([seed])\n",
        "\n",
        "        output = list(seed)\n",
        "\n",
        "        for _ in range(length - len(seed)):\n",
        "            state = tuple(output[-(self.n - 1):])  # last n-1 tokens\n",
        "            if state in self.model:\n",
        "                next_item = random.choice(self.model[state])\n",
        "            else:\n",
        "                next_item = random.choice(random.choice(list(self.model.values())))\n",
        "            output.append(next_item)\n",
        "\n",
        "        # Convert back to string\n",
        "        if self.mode == \"word\":\n",
        "            return \" \".join(output)\n",
        "        else:\n",
        "            return \"\".join(output)\n",
        "\n",
        "\n",
        "# ---------------- Example Usage ----------------\n",
        "if __name__ == \"__main__\":\n",
        "    sample_text = \"\"\"\n",
        "    Artificial Intelligence is the future of technology.\n",
        "    Machine learning and deep learning are subsets of AI.\n",
        "    Markov chains are used for text generation in natural language processing.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=== Word-level Markov Chain ===\")\n",
        "    word_gen = MarkovChainTextGenerator(mode=\"word\", n=2)\n",
        "    word_gen.train(sample_text)\n",
        "    print(word_gen.generate(length=30))\n",
        "\n",
        "    print(\"\\n=== Character-level Markov Chain ===\")\n",
        "    char_gen = MarkovChainTextGenerator(mode=\"char\", n=3)\n",
        "    char_gen.train(sample_text)\n",
        "    print(char_gen.generate(length=200))\n",
        "\n"
      ]
    }
  ]
}